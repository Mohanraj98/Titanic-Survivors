{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic=pd.read_csv('train.csv', index_col='PassengerId')\n",
    "test_titanic=pd.read_csv('test.csv', index_col='PassengerId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Name title\n",
    "import re\n",
    "def name_title(name_list):\n",
    "    title_list=[]\n",
    "    for name in name_list:\n",
    "        title_list.append(re.split(r\"^([^.]*).*\",  re.split(',', name)[1])[1].strip())\n",
    "    return title_list\n",
    "\n",
    "name_list=list(titanic.Name)\n",
    "title_list=name_title(name_list)\n",
    "titanic['title']=title_list\n",
    "\n",
    "name_list=list(test_titanic.Name)\n",
    "title_list=name_title(name_list)\n",
    "test_titanic['title']=title_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.Age.fillna(np.round(titanic[titanic['Pclass']==titanic.Pclass].Age.mean()), inplace=True)\n",
    "titanic.Embarked.fillna('S', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_titanic.Age.fillna(np.round(test_titanic[test_titanic['Pclass']==test_titanic.Pclass].Age.mean()), inplace=True)\n",
    "test_titanic.Fare.fillna(np.round(test_titanic[test_titanic['Pclass']==test_titanic.Pclass].Fare.mean()), inplace=True)\n",
    "test_titanic.Embarked.fillna('S', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHANGES1\n",
    "\n",
    "titanic['relatives']=titanic['SibSp']+titanic['Parch']\n",
    "titanic['FarePH']=titanic['Fare']/(titanic['relatives']+1)\n",
    "titanic=titanic.drop(['Ticket', 'Cabin','Name', 'Fare'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHANGES2\n",
    "\n",
    "test_titanic['relatives']=test_titanic['SibSp']+test_titanic['Parch']\n",
    "test_titanic['FarePH']=test_titanic['Fare']/(test_titanic['relatives']+1)\n",
    "test_titanic=test_titanic.drop(['Ticket', 'Cabin', 'Name', 'Fare'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Survived   Age  SibSp  Parch  relatives    FarePH  Pclass_1  \\\n",
      "PassengerId                                                                \n",
      "1                   0  22.0      1      0          1   3.62500         0   \n",
      "2                   1  38.0      1      0          1  35.64165         1   \n",
      "3                   1  26.0      0      0          0   7.92500         0   \n",
      "4                   1  35.0      1      0          1  26.55000         1   \n",
      "5                   0  35.0      0      0          0   8.05000         0   \n",
      "\n",
      "             Pclass_2  Pclass_3  Sex_female  ...  title_Master  title_Miss  \\\n",
      "PassengerId                                  ...                             \n",
      "1                   0         1           0  ...             0           0   \n",
      "2                   0         0           1  ...             0           0   \n",
      "3                   0         1           1  ...             0           1   \n",
      "4                   0         0           1  ...             0           0   \n",
      "5                   0         1           0  ...             0           0   \n",
      "\n",
      "             title_Mlle  title_Mme  title_Mr  title_Mrs  title_Ms  title_Rev  \\\n",
      "PassengerId                                                                    \n",
      "1                     0          0         1          0         0          0   \n",
      "2                     0          0         0          1         0          0   \n",
      "3                     0          0         0          0         0          0   \n",
      "4                     0          0         0          1         0          0   \n",
      "5                     0          0         1          0         0          0   \n",
      "\n",
      "             title_Sir  title_the Countess  \n",
      "PassengerId                                 \n",
      "1                    0                   0  \n",
      "2                    0                   0  \n",
      "3                    0                   0  \n",
      "4                    0                   0  \n",
      "5                    0                   0  \n",
      "\n",
      "[5 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "titanic.Sex=titanic.Sex.astype('category')\n",
    "titanic.Embarked =titanic.Embarked.astype('category')\n",
    "titanic.Pclass =titanic.Pclass.astype('category')\n",
    "titanic.title =titanic.title.astype('category')\n",
    "\n",
    "titanic=pd.get_dummies(titanic)\n",
    "print(titanic.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Age  SibSp  Parch  relatives    FarePH  Pclass_1  Pclass_2  \\\n",
      "PassengerId                                                                \n",
      "892          34.5      0      0          0  7.829200         0         0   \n",
      "893          47.0      1      0          1  3.500000         0         0   \n",
      "894          62.0      0      0          0  9.687500         0         1   \n",
      "895          27.0      0      0          0  8.662500         0         0   \n",
      "896          22.0      1      1          2  4.095833         0         0   \n",
      "\n",
      "             Pclass_3  Sex_female  Sex_male  ...  Embarked_S  title_Col  \\\n",
      "PassengerId                                  ...                          \n",
      "892                 1           0         1  ...           0          0   \n",
      "893                 1           1         0  ...           1          0   \n",
      "894                 0           0         1  ...           0          0   \n",
      "895                 1           0         1  ...           1          0   \n",
      "896                 1           1         0  ...           1          0   \n",
      "\n",
      "             title_Dona  title_Dr  title_Master  title_Miss  title_Mr  \\\n",
      "PassengerId                                                             \n",
      "892                   0         0             0           0         1   \n",
      "893                   0         0             0           0         0   \n",
      "894                   0         0             0           0         1   \n",
      "895                   0         0             0           0         1   \n",
      "896                   0         0             0           0         0   \n",
      "\n",
      "             title_Mrs  title_Ms  title_Rev  \n",
      "PassengerId                                  \n",
      "892                  0         0          0  \n",
      "893                  1         0          0  \n",
      "894                  0         0          0  \n",
      "895                  0         0          0  \n",
      "896                  1         0          0  \n",
      "\n",
      "[5 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "test_titanic.Sex=test_titanic.Sex.astype('category')\n",
    "test_titanic.Embarked =test_titanic.Embarked.astype('category')\n",
    "test_titanic.Pclass =test_titanic.Pclass.astype('category')\n",
    "test_titanic.title =test_titanic.title.astype('category')\n",
    "\n",
    "test_titanic=pd.get_dummies(test_titanic)\n",
    "print(test_titanic.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic=titanic.drop(['Sex_male', 'Embarked_S'], axis=1)\n",
    "test_titanic=test_titanic.drop(['Sex_male', 'Embarked_S'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standard Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "titanic.Age=scaler.fit_transform(np.array(titanic.Age).reshape(-1, 1))\n",
    "# titanic.Fare=scaler.fit_transform(np.array(titanic.Fare).reshape(-1, 1))\n",
    "titanic.relatives=scaler.fit_transform(np.array(titanic.relatives).reshape(-1, 1))\n",
    "titanic.FarePH=scaler.fit_transform(np.array(titanic.FarePH).reshape(-1, 1))\n",
    "\n",
    "\n",
    "test_titanic.Age=scaler.fit_transform(np.array(test_titanic.Age).reshape(-1, 1))\n",
    "# test_titanic.Fare=scaler.fit_transform(np.array(test_titanic.Fare).reshape(-1, 1))\n",
    "test_titanic.relatives=scaler.fit_transform(np.array(test_titanic.relatives).reshape(-1, 1))\n",
    "test_titanic.FarePH=scaler.fit_transform(np.array(test_titanic.FarePH).reshape(-1, 1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For prediction Score\n",
    "from sklearn.model_selection import train_test_split\n",
    "X=titanic.drop(['Survived'], axis=1)\n",
    "y=titanic['Survived']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)\n",
    "\n",
    "\n",
    "# #For Kaggle Competition\n",
    "# X_train=titanic.drop(['Survived'], axis=1)\n",
    "# y_train=titanic['Survived']\n",
    "# X_test=test_titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "PID=X_test.index\n",
    "results=pd.DataFrame()\n",
    "results['PassengerId']=PID\n",
    "# print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding left over columns to Test dataset (Kaggle)\n",
    "train_col=X_train.columns\n",
    "test_col=X_test.columns\n",
    "\n",
    "add_test_title=list(set(train_col) - set(test_col))\n",
    "for title in add_test_title:\n",
    "    X_test[title]=0\n",
    "\n",
    "add_train_title=list(set(test_col) - set(train_col))\n",
    "for title in add_train_title:\n",
    "    X_train[title]=0 \n",
    "\n",
    "# X_train=X_train.drop(drop_columns, axis=1)\n",
    "# X_test=X_test.drop(drop_columns, axis=1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8268156424581006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Steve\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#logistic Regression\n",
    "from sklearn.linear_model import  LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "lr_pred= logreg.predict(X_test)\n",
    "\n",
    "# log_results=results\n",
    "# log_results['Survived']=lr_pred\n",
    "\n",
    "print(\"Accuracy:\",accuracy_score(y_test, lr_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6201117318435754\n"
     ]
    }
   ],
   "source": [
    "# Naive  Bayes Algorithm\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "gnb = GaussianNB() \n",
    "gnb.fit(X_train, y_train)\n",
    "nb_pred = gnb.predict(X_test) \n",
    "\n",
    "# NB_results=results\n",
    "# NB_results['Survived']=nb_pred\n",
    "\n",
    "print(\"Accuracy:\",accuracy_score(y_test, nb_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i value: 1     Acc: 0.770949720670391\n",
      "i value: 2     Acc: 0.8044692737430168\n",
      "i value: 3     Acc: 0.8435754189944135\n",
      "i value: 4     Acc: 0.8268156424581006\n",
      "i value: 5     Acc: 0.8324022346368715\n",
      "i value: 6     Acc: 0.8324022346368715\n",
      "i value: 7     Acc: 0.8156424581005587\n",
      "i value: 8     Acc: 0.8044692737430168\n",
      "i value: 9     Acc: 0.8156424581005587\n"
     ]
    }
   ],
   "source": [
    "#KNN Algorithm finding best fit\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "for i in range(1, 10):\n",
    "    classifier = KNeighborsClassifier(n_neighbors=i)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    print(\"i value:\",i,\"    Acc:\",accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8435754189944135\n"
     ]
    }
   ],
   "source": [
    "#KNN Algorithm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "knn.fit(X_train, y_train)\n",
    "knn_pred=knn.predict(X_test)\n",
    "\n",
    "# KNN_results=results\n",
    "# KNN_results['Survived']=knn_pred\n",
    "\n",
    "print(\"Accuracy:\",accuracy_score(y_test, knn_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8379888268156425\n"
     ]
    }
   ],
   "source": [
    "#Random Forest Algorithm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators= 100)\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "rf_pred= rf.predict(X_test)\n",
    "\n",
    "# RF_results=results\n",
    "# RF_results['Survived']=rf_pred\n",
    "\n",
    "print(\"Accuracy:\",accuracy_score(y_test, rf_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   29.0s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  4.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 2000, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'auto', 'max_depth': 50, 'bootstrap': False}\n"
     ]
    }
   ],
   "source": [
    "#Random Forest Tuning\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print(rf_random.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8547486033519553\n"
     ]
    }
   ],
   "source": [
    "#Random Forest Algorithm-2\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators= 2000, min_samples_split= 10,  min_samples_leaf= 2, max_features= 'auto',\n",
    "                            max_depth= 50, bootstrap= False)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_pred2= rf.predict(X_test)\n",
    "\n",
    "# RF_results2=results\n",
    "# RF_results2['Survived']=rf_pred2\n",
    "\n",
    "print(\"Accuracy:\",accuracy_score(y_test, rf_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        features  importance\n",
      "22      title_Mr    0.188195\n",
      "8     Sex_female    0.172062\n",
      "4         FarePH    0.170327\n",
      "0            Age    0.109130\n",
      "7       Pclass_3    0.059569\n",
      "3      relatives    0.052197\n",
      "19    title_Miss    0.051412\n",
      "23     title_Mrs    0.049213\n",
      "5       Pclass_1    0.035644\n",
      "1          SibSp    0.033821\n",
      "2          Parch    0.017244\n",
      "18  title_Master    0.014431\n",
      "6       Pclass_2    0.014207\n",
      "10    Embarked_Q    0.013236\n",
      "9     Embarked_C    0.012064\n",
      "25     title_Rev    0.004717\n",
      "14      title_Dr    0.001640\n"
     ]
    }
   ],
   "source": [
    "#Feature Extraction\n",
    "score=[]\n",
    "for name, importance in zip(X_train.columns, rf.feature_importances_):\n",
    "    score.append(importance)\n",
    "\n",
    "score_df=pd.DataFrame(list(zip(X_train.columns, score)), columns=['features', 'importance'])\n",
    "score_df= score_df.sort_values(by=['importance'], ascending=False)[:17]\n",
    "feat=list(score_df['features'])\n",
    "\n",
    "print(score_df)\n",
    "\n",
    "drop_columns=list(set(X_train)-set(feat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7821229050279329\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt= DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)\n",
    "dt_pred= dt.predict(X_test)\n",
    "\n",
    "# DT_results=results\n",
    "# DT_results['Survived']=dt_pred\n",
    "\n",
    "print(\"Accuracy:\",accuracy_score(y_test, dt_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6983240223463687\n"
     ]
    }
   ],
   "source": [
    "#Stochastic Gradient Descent\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd = SGDClassifier(max_iter=5, tol=None)\n",
    "sgd.fit(X_train, y_train)\n",
    "sgd_pred = sgd.predict(X_test)\n",
    "\n",
    "# SGD_results=results\n",
    "# SGD_results['Survived']=sgd_pred\n",
    " \n",
    "print(\"Accuracy:\",accuracy_score(y_test, sgd_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8491620111731844\n"
     ]
    }
   ],
   "source": [
    "#Voting/Stacking Classifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "voting_clf = VotingClassifier(estimators=[ ('KNN', knn), ('RanFor', rf)], voting='hard')\n",
    "voting_clf.fit(X_train, y_train)\n",
    "y_pred= voting_clf.predict(X_test)\n",
    "\n",
    "# V_results=results\n",
    "# V_results['Survived']=y_pred\n",
    "\n",
    "print(\"Accuracy:\",accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log_results.to_csv('log_results.csv',index=False)\n",
    "# # NB_results.to_csv('NB_results.csv',index=False)\n",
    "# KNN_results.to_csv('KNN_results.csv',index=False)\n",
    "# RF_results2.to_csv('RF_results.csv',index=False)\n",
    "# # DT_results.to_csv('DT_results.csv',index=False)\n",
    "# # SGD_results.to_csv('SGD_results.csv',index=False)\n",
    "# # V_results.to_csv('V_results.csv',index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
